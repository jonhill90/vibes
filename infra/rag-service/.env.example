# RAG Service - Environment Configuration
# Copy this file to .env and update values for your environment

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# PostgreSQL database name
POSTGRES_DB=ragservice

# PostgreSQL username
POSTGRES_USER=raguser

# PostgreSQL password
# SECURITY: Change this in production!
POSTGRES_PASSWORD=ragpass123

# Database connection string for backend
# Format: postgresql://user:password@host:port/database
# Use 'postgres' as hostname when running in Docker Compose (service name)
# Use 'localhost' when running backend locally
DATABASE_URL=postgresql://raguser:ragpass123@postgres:5432/ragservice

# Database connection pool configuration
DATABASE_POOL_MIN_SIZE=10
DATABASE_POOL_MAX_SIZE=20

# Database port (exposed to host)
POSTGRES_PORT=5433

# =============================================================================
# BACKEND CONFIGURATION
# =============================================================================

# FastAPI server port
API_PORT=8001

# MCP server port (for agent tools via streamable HTTP)
MCP_PORT=8002

# MCP configuration
MCP_PAYLOAD_MAX_LENGTH=1000
MCP_PAGINATION_MAX=20

# CORS allowed origins (comma-separated)
# Add all frontend URLs that need access to the API
CORS_ORIGINS=http://localhost:5173,http://localhost:5174

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# EMBEDDING SERVICE CONFIGURATION
# =============================================================================

# OpenAI API key for embeddings
OPENAI_API_KEY=your-openai-api-key-here

# Embedding model to use
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Embedding dimensions (1536 for text-embedding-3-small)
OPENAI_EMBEDDING_DIMENSION=1536

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=100

# =============================================================================
# QDRANT VECTOR DATABASE CONFIGURATION
# =============================================================================

# Qdrant server URL
# Use http://qdrant:6333 in Docker Compose
# Use http://localhost:6333 for local development
QDRANT_URL=http://qdrant:6333

# Qdrant collection name for document vectors
QDRANT_COLLECTION_NAME=documents

# Qdrant REST API port (exposed to host)
QDRANT_REST_PORT=6333

# Qdrant gRPC API port (exposed to host)
QDRANT_GRPC_PORT=6334

# =============================================================================
# SEARCH CONFIGURATION
# =============================================================================

# Enable hybrid search (vector + full-text)
# Set to true to combine vector similarity with PostgreSQL full-text search
# Set to false for vector-only search
USE_HYBRID_SEARCH=false

# Hybrid search weights (must sum to 1.0)
# Vector weight: importance of semantic similarity (default: 0.7)
HYBRID_VECTOR_WEIGHT=0.7

# Text weight: importance of keyword matching (default: 0.3)
HYBRID_TEXT_WEIGHT=0.3

# Hybrid candidate multiplier (fetch limit * multiplier from each strategy)
# Higher values improve result quality but increase latency
HYBRID_CANDIDATE_MULTIPLIER=5

# Vector similarity threshold (0.0 to 1.0)
# Results below this threshold are filtered out
SIMILARITY_THRESHOLD=0.05

# =============================================================================
# DOCUMENT CHUNKING CONFIGURATION
# =============================================================================

# Target token count per chunk
CHUNK_SIZE=500

# Token overlap between consecutive chunks
# Helps maintain context across chunk boundaries
CHUNK_OVERLAP=50

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

# Frontend development server port
FRONTEND_PORT=5173

# Backend API URL for frontend
# Use http://localhost:8001 for local development
# Use http://backend:8001 for Docker Compose internal networking
VITE_API_URL=http://localhost:8001

# API base path for frontend requests
VITE_API_BASE_PATH=/api

# =============================================================================
# GENERAL CONFIGURATION
# =============================================================================

# Environment mode (development, staging, production)
ENVIRONMENT=development

# =============================================================================
# USAGE NOTES
# =============================================================================
#
# 1. Copy this file:
#    cp .env.example .env
#
# 2. Add your OpenAI API key in .env
#
# 3. Update other values in .env for your environment
#
# 4. Start services:
#    docker-compose up -d
#
# 5. View logs:
#    docker-compose logs -f
#
# 6. Stop services:
#    docker-compose down
#
# 7. Reset database (WARNING: deletes all data):
#    docker-compose down -v
#    docker-compose up -d
#
# =============================================================================
# PRODUCTION DEPLOYMENT
# =============================================================================
#
# For production deployments, ensure:
# - Use strong, unique POSTGRES_PASSWORD
# - Set ENVIRONMENT=production
# - Update CORS_ORIGINS to production frontend URL only
# - Use HTTPS URLs for VITE_API_URL
# - Set LOG_LEVEL=WARNING or ERROR
# - Secure OPENAI_API_KEY using secrets management
# - Configure database backups for ragservice-db-data volume
#
